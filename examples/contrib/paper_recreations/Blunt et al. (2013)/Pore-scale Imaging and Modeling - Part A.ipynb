{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blunt et al. (2013)\n",
    "## Pore Scale Imaging and Modeling Section I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we have selected a comprehensive paper related to [pore scale imaging and modeling](https://www.sciencedirect.com/science/article/pii/S0309170812000528). The goal of this example is to investigate the permeability of different rock samples. As there are different samples, we just put the general code here which can be applicable for other samples as well. Therefore, the results will be given in figures.\n",
    "\n",
    "The structure of this report goes as follows:\n",
    "\n",
    "- Pore Newtork Extraction Method\n",
    "- Applying Stokes flow for permeability estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pore Newtork Extraction Method\n",
    "In this project, we have used [SNOW algorithm](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.96.023307) in [Porespy](http://porespy.org/) which is a network extraction method based on marker-based watershed segmentation. The SNOW algorithm concludes four main steps:\n",
    "\n",
    "- Prefiltering the distance map\n",
    "- Eliminating peaks on saddles and plateaus\n",
    "- Merging peaks that are too near each other\n",
    "- Assigning void voxels to the appropriate pore using a marker-based watershed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of prefiltering parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, use of right parameters for filtering may enhance the reliablity of the results. We use a gaussian filter with a spherical\n",
    "structuring element of radius R. The sigma or\n",
    "standard deviation of the convolution kernel is an adjustable\n",
    "parameter, the effect of which can be studied with the following code. Another parameter to be considered is the radius R, which is also investigated for the same sample. Choosing the right value affects the smoothness of the resulting partitioned regions. In other words, this will prevent oversmoothing and loss of a great amount of data from the original image. There is a trade off between preserving the data and filtering. We should find an optimum point for this parameters. The idea have been shown in Fig.4 of the paper. We have used the same idea to change the snowpartitioning algorithm so that we can have our desired output for this part. As long as Network extraction will take more time, we first investigate the effect of choosing different R and sigma as a preprocess, then use the righ parameters for network extraction and call SNOW algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code is related to this prefiltering step (this is a part of the whole code which is related to prefiltering)Changes in the filtering functions so that we can have the initial and final number of local maxima in a dictionarry array resultsB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snow_partitioning_test(im, r_max=4, sigma=0.4, return_all=False):\n",
    "    tup = namedtuple('results', field_names=['im', 'dt', 'peaks', 'regions'])\n",
    "    results = {\n",
    "        'r_max': r_max, 'sigma': sigma,\n",
    "        'Initial number of peaks:': [],\n",
    "        'Peaks after trimming saddle points:': [],\n",
    "        'Peaks after trimming nearby peaks:':[]\n",
    "    }\n",
    "    print('-' * 80)\n",
    "    print(\"Beginning SNOW Algorithm\")\n",
    "    im_shape = np.array(im.shape)\n",
    "    if im.dtype == 'bool':\n",
    "        print('Peforming Distance Transform')\n",
    "        if np.any(im_shape == 1):\n",
    "            ax = np.where(im_shape == 1)[0][0]\n",
    "            dt = spim.distance_transform_edt(input=im.squeeze())\n",
    "            dt = np.expand_dims(dt, ax)\n",
    "        else:\n",
    "            dt = spim.distance_transform_edt(input=im)\n",
    "    else:\n",
    "        dt = im\n",
    "        im = dt > 0\n",
    "\n",
    "    tup.im = im\n",
    "    tup.dt = dt\n",
    "\n",
    "    if sigma > 0:\n",
    "        print('Applying Gaussian blur with sigma =', str(sigma))\n",
    "        dt = spim.gaussian_filter(input=dt, sigma=sigma)\n",
    "\n",
    "    peaks = find_peaks(dt=dt, r_max=r_max)\n",
    "    print('Initial number of peaks: ', spim.label(peaks)[1])\n",
    "    resultsB['Initial number of peaks:']=spim.label(peaks)[1]\n",
    "    peaks = trim_saddle_points(peaks=peaks, dt=dt, max_iters=500)\n",
    "    print('Peaks after trimming saddle points: ', spim.label(peaks)[1])\n",
    "    resultsB['Peaks after trimming saddle points:']=spim.label(peaks)[1]\n",
    "    peaks = trim_nearby_peaks(peaks=peaks, dt=dt)\n",
    "    peaks, N = spim.label(peaks)\n",
    "    print('Peaks after trimming nearby peaks: ', N)\n",
    "    resultsB['Peaks after trimming nearby peaks:']=N\n",
    "    tup.peaks = peaks\n",
    "    regions = watershed(image=-dt, markers=peaks, mask=dt > 0)\n",
    "    regions = randomize_colors(regions)\n",
    "    if return_all:\n",
    "        tup.regions = regions\n",
    "        return tup\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageinit = im\n",
    "Resultslast = {}\n",
    "R_max = [2,4,6,8,12,15,20]\n",
    "Sigmax = [0.25,0.35,0.5,0.65]\n",
    "c = -1\n",
    "for j in range(len(Sigmax)):\n",
    "    for i in range(len(R_max)):\n",
    "        c = c+1\n",
    "        r_max = R_max[i]\n",
    "        sigma = Sigmax[j]\n",
    "        results = snow_partitioning(im=imageinit,r_max=r_max, sigma=sigma, return_all=False)\n",
    "        Resultslast[c] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marching Cube Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on new porespy package, there is also some changes in SNOW algorithm previous version. In the previous version the area was estimated as the number of voxels on the surface multiplied by the area of\n",
    "one voxel face. Now the user can have the chance to use [Marching Cube](https://en.wikipedia.org/wiki/Marching_cubes) algorithm. The idea ofd the algorithm is to find what portion of the cube is inside the image by using a triangular mesh marching through the cube to fine the best interface between inner and outer part of the image. Generally speaking this will decrease the voxelated representation of the image which itself increase the accuracy of the calculations. In the voxel based surface area calculation, we assign the whole voxel to the surface even though only half of that voxel might be within the surface. So it may lead to overestimation. It may make the process slower, but provides better results. To understand the algorithm, we have shown here a [2D example](http://www.cs.carleton.edu/cs_comps/0405/shape/marching_cubes.html). Imagine an aritrary shaped image. If we mesh the area with a square mesh (representative as pixels which will be cubes in 3D as voxels), we have the follwing image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/1L1ix7A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red corners are within the image, the blue ones are outside. Each square which has not 4 same color corner will be marched until get the most precise triangular mesh as the boundary. First the purple dots locate the center of each edge, which we know this is a rough estimation. Then the connecting line (surface in 3D) will march through the square area so that finds its way through the boundary at an optimum location. Implementation of the algorithm in the 3D follows the same idea. The following picture is a sketch of [3D implementation](http://www.cs.carleton.edu/cs_comps/0405/shape/marching_cubes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/xNekZog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this option will give better results, we can still turn it off in SNOW algorithm for the sake of time efficiency and still have good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our scriopt for the network extraction is correcrt, we first implemented the same code on Berea Sandstone, the validity of which can be prooved by comparing the results given in the paper. We have additional boundary face pores, but internal pores are approximately the sam as that of SNOW paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permeabilities are: 1.20607725e-12, 1.0525892e-12, 1.18140011e-12\n",
    "\n",
    "average permeability is: 1.1466888534117068e-12\n",
    "\n",
    "The results are very close to the SNOW paper (which was 1.29e-12 from Image Analysis) . This will ensure us about our script written for the network extraction and permeability calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figures illustrate one segment of CT images of rock samples (MG and Bentheimer) in binarized version:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/sZoo5xO.jpg\" style=\"width: 30%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/TwAvbcu.jpg\" style=\"width: 30%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/ls3ar6c.jpg\" style=\"width: 30%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sample                           | Size           | Resolution | Porosity |\n",
    "| :---                             | :---           |:---        |:---      |\n",
    "| Mount Gambier (our model)        | 512 512 512    | 3.024  μm  | 0.436    |\n",
    "| Mount Gambier (paper)            | 350 350 350    | 9  μm      | 0.556    | \n",
    "| Bentheimer Sandstone (our model) | 300 300 300    | 3   μm     | 0.2      | \n",
    "| Bentheimer Sandstone (paper)     | 1000 1000 1000 | 3.0035  μm | 0.217    | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the script we have written for MG sample. The same code have been applied on other samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import porespy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import openpnm as op\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "ws = op.Workspace()\n",
    "ws.clear()\n",
    "ws.keys()\n",
    "proj = ws.new_project()\n",
    "from skimage import io\n",
    "im = io.imread('MG.tif')\n",
    "imtype=im.view()\n",
    "print(imtype)\n",
    "digits = np.prod(np.array(im.shape))\n",
    "logi = (np.sum(im==0)+np.sum(im==1))==digits\n",
    "if logi == True:\n",
    "    print('There is no noise')\n",
    "else:\n",
    "    print('Please check your input image for noise')\n",
    "print(im.shape)\n",
    "imtype = im.view()\n",
    "print(imtype)\n",
    "im = np.array(im, dtype=bool)\n",
    "# Inversion of 0s and 1s in binarized image to represent 1 for pores and 0 for solids\n",
    "im = ~im \n",
    "print(ps.metrics.porosity(im))\n",
    "plt.imshow(ps.visualization.sem(im), cmap=plt.cm.bone)  \n",
    "net = ps.network_extraction.snow(im, voxel_size=3.024e-6,\n",
    "         boundary_faces=['top', 'bottom', 'left', 'right', 'front', 'back'],\n",
    "         marching_cubes_area=False) # voxel size and marching cube can be changed for each specific sample\n",
    "pn = op.network.GenericNetwork()\n",
    "pn.update(net)\n",
    "print(pn)\n",
    "a = pn.check_network_health()\n",
    "op.topotools.trim(network=pn,pores=a['trim_pores'])\n",
    "print(pn)\n",
    "ps.io.to_vtk(path='MGvt',im=im.astype(sp.int8))\n",
    "mgr = op.Workspace()\n",
    "# The generated .pnm file will be used as input for simulations (permeability calculation, etc.)\n",
    "mgr.save_workspace('MountGampn.pnm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we ensure the validity of our script, we implement the network extraction on the samples of the study. Their network properties are given in the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of pores | Number of throats | Volume (mm3) | Coordination number |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Mount Gambier Carbonate (512) | 5780 (4679 internal) | 10128 (9027 internal) | 27.65 | 3.504 |\n",
    "| MG Paper (350) | 22665 (257 elements isolated) | 84593 | 31.3 | 7.41 |\n",
    "| Bentheimer Sandstone (1000) | 26588 (23329  internal) | 48911 (45652 internal) | 27.1 | 3.68 |\n",
    "| Bentheimer Paper (300) | Not given | Not given | 19.68 | Not given |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Comments:\n",
    "\n",
    "As shown in the table, we have a good match on the average coordination numbers, but the number of pores and throats are different. This is related to the difference between SNOW and maximall method which have been done in the ICL. The snow algorithm will have larger pores which decreases the number of pores and throats. \n",
    "\n",
    "The porosity is being calculated from the voxelated image in a similar manner of the paper.  The permeabilities have been calculated using stokes flow algorithm. The difference might be related to the error which lays behind the parameters in filtering process (sigma, R). We have used default values of sigma=0.4 and R=5 in all samples, which may lead to misrepresentation of the network.\n",
    "\n",
    "The difference in permeability may also be related to the different conduit lengths. In the Blunt's paper they have defined a shape factor to account for the non-cylindrical deviation of the throats. This shape factor is whithin the maximal extraction method. In the SNOW algorithm, using the equivalent diameter rather than inscribed diameter for the hydraulic conductance (assumming no P loss in the pores) will provide better results in the permeability calculation.\n",
    "\n",
    "From the Berea sandstone results, we can also comment on the effect of the structures of the rock sample. For sandstones, the morphology is more ideal than carbonates for network extractions. We also get a good result for Bentheimer Sandstone permeability. But for the carbonate cases, it is different. As we see in their CT images, there are Fossil grains (Pebbles in ketton, other fossil shells in two other sample) which provide different length scales of micro to macro pores. For example it is recommended to use multiscale pore network extraction.\n",
    "\n",
    "As long as not any of our sample is the same sample in the Blunt's paper (they are from the same rock but different resolution and size), the slight difference in results is acceptable.\n",
    "\n",
    "Isolated pores and throats will be trimmed using \"topotools\" trimming method after the network extraction.\n",
    "\n",
    "-For the permeability calculation, we need to set inlets and outlets of the media, both of which can be defined by introducing some pores as boundary surface pores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static parameters assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We redefine some parameters of the network by deleting them from the pn dictionary and adding models for them in the geomety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpnm as op\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "mgr = op.Workspace()\n",
    "mgr.clear()\n",
    "mgr.keys()\n",
    "path = Path('../fixtures/PoreScale Imaging/MountGampn.pnm')\n",
    "mgr.load_workspace(path)\n",
    "pn = mgr['proj_03']['net_01']\n",
    "a = pn.check_network_health()\n",
    "op.topotools.trim(network=pn,pores=a['trim_pores'])\n",
    "proj = pn.project\n",
    "print(pn)\n",
    "coord_num_avg=np.mean(pn.num_neighbors(pores=pn.Ps))\n",
    "del pn['pore.area']\n",
    "del pn['throat.conduit_lengths.pore1']\n",
    "del pn['throat.conduit_lengths.pore2']\n",
    "del pn['throat.conduit_lengths.throat']\n",
    "del pn['throat.endpoints.tail']\n",
    "del pn['throat.endpoints.head']\n",
    "del pn['throat.volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we implement the assignment of Geometry, Phase, and Physics to the Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = op.geometry.GenericGeometry(network=pn, pores=pn['pore.all'], throats=pn['throat.all'],project=proj)\n",
    "geom.add_model(propname='throat.endpoints',\n",
    "                model=op.models.geometry.throat_endpoints.spherical_pores)\n",
    "geom.add_model(propname='pore.area',\n",
    "                model=op.models.geometry.pore_cross_sectional_area.sphere)\n",
    "geom.add_model(propname='throat.volume',\n",
    "                model=op.models.geometry.throat_volume.cylinder)\n",
    "geom.add_model(propname='throat.conduit_lengths',\n",
    "                model=op.models.geometry.throat_length.conduit_lengths)\n",
    "oil = op.phases.GenericPhase(network=pn,project=proj)\n",
    "water = op.phases.GenericPhase(network=pn,project=proj)\n",
    "oil['pore.viscosity']=0.547e-3\n",
    "oil['throat.contact_angle'] =180\n",
    "oil['throat.surface_tension'] = 0.072\n",
    "oil['pore.surface_tension']=0.072\n",
    "oil['pore.contact_angle']=180\n",
    "water['throat.contact_angle'] = 0 # first assumming highly water-wet\n",
    "water['pore.contact_angle'] = 0\n",
    "water['throat.surface_tension'] = 0.0483\n",
    "water['pore.surface_tension'] = 0.0483\n",
    "water['pore.viscosity']=0.4554e-3\n",
    "phys_water= op.physics.GenericPhysics(network=pn, phase=water, geometry=geom,project=proj)\n",
    "phys_oil = op.physics.GenericPhysics(network=pn, phase=oil, geometry=geom,project=proj)\n",
    "\n",
    "mod = op.models.physics.hydraulic_conductance.hagen_poiseuille\n",
    "phys_oil.add_model(propname='throat.hydraulic_conductance',\n",
    "                              model=mod)\n",
    "phys_oil.add_model(propname='throat.entry_pressure',\n",
    "                              model=op.models.physics.capillary_pressure.washburn)\n",
    "phys_water.add_model(propname='throat.hydraulic_conductance',\n",
    "                              model=mod)\n",
    "phys_water.add_model(propname='throat.entry_pressure',\n",
    "                              model=op.models.physics.capillary_pressure.washburn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permeability Calculation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StokesFlow class is for simulation of viscous flow. In this class default property names will be set. The main role of this class would be calculation of the hydraulic permeability. Having its effective permeability calculation method, it can deal with nonuniform medias.\n",
    "\n",
    "We first find single phase permeability where the stokes flow is implemented for each phase as if it is the only phase flowing through the porous media. Theis is done as the conductance is the hydraulic conductance. Otherwise, it will change to multiphase conduit conductance. Note that we have defined perm_water and perm_oil in a dictionary so that we have a permeability tensor (directional permeability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have mentioned the permeability will be a tensor, which represents $K_x,K_y,K_z$. Permeability tensor plays an important role in anisotropic medias charactarization. We have also defined relative permeabilities in three directions. We only show the relative permeabilities for one direction in the report, but the code gives us the results for all three directions in the oil and water perm dictionary.\n",
    "\n",
    "We also define methods in which the domain length and area will be calculated. These methods are called within the permeability calculation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_water_single_phase = [None,None,None]\n",
    "K_oil_single_phase = [None,None,None]\n",
    "bounds = [ ['top', 'bottom'], ['left', 'right'],['front', 'back']]\n",
    "\n",
    "[amax, bmax, cmax] = np.max(pn['pore.coords'], axis=0)\n",
    "[amin, bmin, cmin] = np.min(pn['pore.coords'], axis=0)\n",
    "lx = amax-amin\n",
    "ly = bmax-bmin\n",
    "lz = cmax-cmin\n",
    "da = lx*ly\n",
    "dl = lz\n",
    "\n",
    "def top_b(lx,ly,lz):\n",
    "    da = lx*ly\n",
    "    dl = lz\n",
    "    res_2=[da,dl]\n",
    "    return res_2\n",
    "\n",
    "def left_r(lx,ly,lz):\n",
    "    \n",
    "    da = lx*lz\n",
    "    dl = ly\n",
    "    res_2=[da,dl]\n",
    "    return res_2\n",
    "\n",
    "def front_b(lx,ly,lz):\n",
    "    da = ly*lz\n",
    "    dl = lx\n",
    "    res_2=[da,dl]\n",
    "    return res_2\n",
    "\n",
    "options = {0 : top_b(lx,ly,lz),1 : left_r(lx,ly,lz),2 : front_b(lx,ly,lz)}\n",
    "\n",
    "for bound_increment in range(len(bounds)):\n",
    "    BC1_pores = pn.pores(labels=bounds[bound_increment][0])\n",
    "    BC2_pores = pn.pores(labels=bounds[bound_increment][1])\n",
    "    [da,dl]=options[bound_increment]\n",
    "    \n",
    "    # Permeability - water\n",
    "    sf_water = op.algorithms.StokesFlow(network=pn, phase=water)\n",
    "    sf_water.setup(conductance='throat.hydraulic_conductance')\n",
    "    sf_water._set_BC(pores=BC1_pores, bctype='value', bcvalues=100000)\n",
    "    sf_water._set_BC(pores=BC2_pores, bctype='value', bcvalues=1000)\n",
    "    sf_water.run()\n",
    "    K_water_single_phase[bound_increment] = sf_water.calc_effective_permeability(domain_area=da,\n",
    "                                                                                 domain_length=dl,\n",
    "                                                                                 inlets=BC1_pores,\n",
    "                                                                                 outlets=BC2_pores)\n",
    "    proj.purge_object(obj=Stokes_alg_single_phase_water)\n",
    "    \n",
    "    # Permeability - oil\n",
    "    sf_oil = op.algorithms.StokesFlow(network=pn, phase=oil)\n",
    "    sf_oil.setup(conductance='throat.hydraulic_conductance')\n",
    "    sf_oil._set_BC(pores=BC1_pores, bctype='value', bcvalues=1000)\n",
    "    sf_oil._set_BC(pores=BC2_pores, bctype='value', bcvalues=0)\n",
    "    sf_oil.run()\n",
    "    K_oil_single_phase[bound_increment] = sf_oil.calc_effective_permeability(domain_area=da,\n",
    "                                                                             domain_length=dl,\n",
    "                                                                             inlets=BC1_pores,\n",
    "                                                                             outlets=BC2_pores)\n",
    "    proj.purge_object(obj=Stokes_alg_single_phase_oil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for permeability calculation of four samples are given in the following. As we see the results for Bentheimer which is a sand stone rock is very close to the value given in the paper. We have also adjusted the permeabilities of the MGambier by using equivalent diameter instead of pore and throat diameter for the conductance calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sample  | Mount Gambier 512 | Bentheimer 1000  |\n",
    "| --- | --- | --- | \n",
    "|K1 (e-12) |18.93 | 1.57|\n",
    "|K2 (e-12) |23.96 | 1.4|\n",
    "|K3 (e-12) | 12.25| 1.64|\n",
    "| Kavg | 18.38| 1.53 |\n",
    "|Sample paper | Mount Gambier 350 | Bentheimer 300 |\n",
    "|Kavg (from image)| 19.2 | 1.4 |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
